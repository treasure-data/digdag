package io.digdag.cli.profile;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.core.JsonGenerator;
import com.fasterxml.jackson.databind.SerializerProvider;
import com.fasterxml.jackson.databind.annotation.JsonSerialize;
import com.fasterxml.jackson.databind.ser.std.StdSerializer;
import com.google.common.base.Optional;
import com.google.common.math.Stats;
import io.digdag.client.config.Config;
import io.digdag.client.config.ConfigFactory;
import io.digdag.core.session.ArchivedTask;
import io.digdag.core.session.ImmutableArchivedTask;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.time.Duration;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.stream.Collectors;

import static io.digdag.client.DigdagClient.objectMapper;

/**
 * Represents the summary of task analysis and has capability of calculating task start delays and execution durations.
 *
 * In the following cases, start delay analysis skips over a task when
 *
 * 1. the task is dynamically generated by `_error`, `_check` directive or etc.
 *    In this case, `started_at` of the task is set to an unexpectedly later timestamp.
 *    That's because `failure-alert`, `_error` and `_check` are dynamically generated connecting to the parent task
 *    after preceding tasks take some time and we can't tell it apart from actual delay.
 *
 * 2. the task or the parent task doesn't have `started_at`.
 *    This can happen with old archived tasks generated by old implementation.
 *
 * 3. the task has no upstream tasks and the parent is not GROUP_ONLY task type (e.g. the first child task under a `for_each` operator).
 *    In this case, the duration between the parent's `started_at` and the task's one seems unexpectedly larger.
 *    That's because some operators start child tasks after its own operation finishes
 *    (e.g. `td_for_each` operator) and we can't tell it apart from actual delay.
 *
 * 4. the task has any upstream task and the upstream tasks don't have `started_at`.
 *    This happens when the attempt is started by `retry --resume`.
 *    The behavior itself that skipped tasks in a retried attempt have empty `started_at` seems unexpected.
 *    It may be fixed in the future.
 *
 * 5. the task is retried. That's because a retried task directly connects to the parent task
 *    and the `started_at` is recorded after proceeding tasks fail.
 *    The behavior that retried tasks have later `started_at` seems reasonable.
 *    This limitation won't be removed for a while...
 */
public class TasksSummary
{
    private static final Logger logger = LoggerFactory.getLogger(TasksSummary.class);

    private static final Config EMPTY_CONFIG = new ConfigFactory(objectMapper()).create();

    @JsonProperty
    public final long attempts;
    @JsonProperty
    public final long totalTasks;
    @JsonProperty
    public final long totalRunTasks;
    @JsonProperty
    public final long totalSuccessTasks;
    @JsonProperty
    public final long totalErrorTasks;

    @JsonProperty
    public final ArchivedTask mostDelayedTask;
    @JsonProperty
    public final TasksStats startDelayMillis;
    @JsonProperty
    public final TasksStats execDurationMillis;

    public TasksSummary(
            long attempts,
            long totalTasks,
            long totalRunTasks,
            long totalSuccessTasks,
            long totalErrorTasks,
            ArchivedTask mostDelayedTask,
            TasksStats startDelayMillis,
            TasksStats execDurationMillis)
    {
        this.attempts = attempts;
        this.totalTasks = totalTasks;
        this.totalRunTasks = totalRunTasks;
        this.totalSuccessTasks = totalSuccessTasks;
        this.totalErrorTasks = totalErrorTasks;
        this.mostDelayedTask = mostDelayedTask;
        this.startDelayMillis = startDelayMillis;
        this.execDurationMillis = execDurationMillis;
    }

    static class Builder
    {
        long attempts;
        long totalTasks;
        long totalRunTasks;
        long totalSuccessTasks;
        long totalErrorTasks;

        long maxDelayMillis;
        ArchivedTask mostDelayedTask;

        final TasksStats.Builder startDelayMillis = new TasksStats.Builder();
        final TasksStats.Builder execDurationMillis = new TasksStats.Builder();

        TasksSummary build()
        {
            return new TasksSummary(
                    attempts,
                    totalTasks,
                    totalRunTasks,
                    totalSuccessTasks,
                    totalErrorTasks,
                    mostDelayedTask,
                    startDelayMillis.build(),
                    execDurationMillis.build()
            );
        }
    }

    static void updateBuilderWithTask(
            Builder builder,
            boolean isRoot,
            Map<Long, ArchivedTask> taskMap,
            Set<String> evaluatedTaskNames,
            ArchivedTask task)
    {
        // It's possible some old group tasks don't have `started_at`,
        // so skip if it doesn't exists
        // (This case corresponds to #2 in the comment above)
        if (!isRoot && task.getStartedAt().isPresent()) {
            builder.totalRunTasks++;
            // The stats of exec durations handle both group and non-group tasks for now.
            // There may be room to discuss about it.
            builder.execDurationMillis.add(
                    Duration.between(task.getStartedAt().get(), task.getUpdatedAt()).toMillis());

            // To know the delay of a task, it's needed to choose the correct previous task
            // considering sequential execution and/or nested task.
            Optional<Instant> timestampWhenTaskIsReady = Optional.absent();
            if (task.getUpstreams().isEmpty()) {
                // This task is the first child task of a group task
                Optional<Long> parentId = task.getParentId();
                if (parentId.isPresent()) {
                    ArchivedTask previousTask = taskMap.get(parentId.get());
                    // If the parent task is a pure group task having no actual tasks,
                    // `started_at` should be used as previous task's timestamp
                    // since `updated_at` is updated after all child tasks finish.
                    if (previousTask.getTaskType().isGroupingOnly()) {
                        // Just for old archived tasks
                        // (This case corresponds to #2 in the comment above)
                        if (previousTask.getStartedAt().isPresent()) {
                            // This task was executed after the previous group task started,
                            // so check the previous one's `started_at`
                            timestampWhenTaskIsReady = Optional.of(previousTask.getStartedAt().get());
                        }
                    }
                    else {
                        // Task start delay analysis should be skipped if the task is the first child of non GROUP_ONLY task
                        // (This case corresponds to #3 in the comment above)
                        timestampWhenTaskIsReady = Optional.absent();
                    }
                }
            } else {
                // This task is executed sequentially. Get the latest `updated_at` of upstream tasks.
                //
                // This way also can deal with `_parallel`'s `limit: N` option since
                // tasks in the second or later parallel tasks set have
                // previous parallel task IDs in `upstreams` field
                long previousTaskId = task.getUpstreams().stream()
                        .max(Comparator.comparingLong(
                                id -> taskMap.get(id).getUpdatedAt().toEpochMilli()))
                        .get();
                ArchivedTask previousTask = taskMap.get(previousTaskId);
                // Task start delay analysis should be skipped if the task was skipped in an retried attempt
                // (This case corresponds to #4 in the comment above)
                if (previousTask.getStartedAt().isPresent()) {
                    // This task was executed after the previous task finished,
                    // so check the previous one's `updated_at`
                    timestampWhenTaskIsReady = Optional.of(previousTask.getUpdatedAt());
                }
            }

            // Task start delay analysis for this task should be skipped if it was dynamically generated.
            // (This case corresponds to #1 in the comment above)
            if (task.getFullName().endsWith("^check")
                    || task.getFullName().endsWith("^error")
                    || task.getFullName().endsWith("^failure-alert")) {
                timestampWhenTaskIsReady = Optional.absent();
            }

            if (timestampWhenTaskIsReady.isPresent()
                    // Task start delay analysis for this task should be skipped if it was retried with `_retry`.
                    // (This case corresponds to #5 in the comment above)
                    && !evaluatedTaskNames.contains(task.getFullName())) {
                long delayMillis = Duration.between(timestampWhenTaskIsReady.get(), task.getStartedAt().get()).toMillis();
                builder.startDelayMillis.add(delayMillis);
                if (delayMillis > builder.maxDelayMillis) {
                    // Mask some unnecessary fields
                    builder.mostDelayedTask = ImmutableArchivedTask.builder()
                            .attemptId(task.getAttemptId())
                            .id(task.getId())
                            .fullName(task.getFullName())
                            .taskType(task.getTaskType())
                            .parentId(task.getParentId())
                            .error(task.getError())
                            .report(task.getReport())
                            .state(task.getState())
                            .stateFlags(task.getStateFlags())
                            .upstreams(task.getUpstreams())
                            .resumingTaskId(task.getResumingTaskId())
                            .config(task.getConfig())
                            .retryCount(task.getRetryCount())
                            .retryAt(task.getRetryAt())
                            .startedAt(task.getStartedAt())
                            .updatedAt(task.getUpdatedAt())
                            .subtaskConfig(EMPTY_CONFIG)
                            .exportParams(EMPTY_CONFIG)
                            .storeParams(EMPTY_CONFIG)
                            .stateParams(EMPTY_CONFIG)
                            .build();
                    builder.maxDelayMillis = delayMillis;
                }
            }

            if (task.getState().isError()) {
                builder.totalErrorTasks++;
            } else {
                builder.totalSuccessTasks++;
            }
            evaluatedTaskNames.add(task.getFullName());
        }
    }

    // This method is called for each attempt and
    // accumulates stats in `builder`.
    static void updateBuilderWithTasks(
            Builder builder,
            List<ArchivedTask> originalTasks)
    {
        builder.attempts++;

        // Sort tasks by `id` just in case
        List<ArchivedTask> tasks = originalTasks.stream()
                // Make it fail if unexpected overflow happens just in case
                .sorted((a, b) -> Math.toIntExact(a.getId() - b.getId()))
                .collect(Collectors.toList());

        // Create a task map for lookup by task id
        Map<Long, ArchivedTask> taskMap = new HashMap<>(tasks.size());
        for (ArchivedTask task : tasks) {
            taskMap.put(task.getId(), task);
        }

        builder.totalTasks += tasks.size() - 1; // Remove a root task

        // Calculate the delays of task invocations
        boolean isRoot = true;
        HashSet<String> evaluatedTaskNames = new HashSet<>();
        for (ArchivedTask task : tasks) {
            updateBuilderWithTask(builder, isRoot, taskMap, evaluatedTaskNames, task);
            isRoot = false;
        }
    }

    @Override
    public String toString()
    {
        return "TasksSummary{" +
                "attempts=" + attempts +
                ", totalTasks=" + totalTasks +
                ", totalRunTasks=" + totalRunTasks +
                ", totalSuccessTasks=" + totalSuccessTasks +
                ", totalErrorTasks=" + totalErrorTasks +
                ", startDelayMillis=" + startDelayMillis +
                ", execDurationMillis=" + execDurationMillis +
                '}';
    }

    @JsonSerialize(using = TasksStatsSerializer.class)
    static class TasksStats
    {
        final Optional<Stats> stats;

        TasksStats(Optional<Stats> stats)
        {
            this.stats = stats;
        }

        static TasksStats of(Collection<Long> values)
        {
            if (values.isEmpty()) {
                return new TasksStats(Optional.absent());
            } else {
                return new TasksStats(Optional.of(Stats.of(values)));
            }
        }

        Long count()
        {
            return stats.transform(x -> Double.valueOf(x.count()).longValue()).orNull();
        }

        Long min()
        {
            return stats.transform(x -> Double.valueOf(x.min()).longValue()).orNull();
        }

        Long max()
        {
            return stats.transform(x -> Double.valueOf(x.max()).longValue()).orNull();
        }

        Long mean()
        {
            return stats.transform(x -> Double.valueOf(x.mean()).longValue()).orNull();
        }

        Long stdDev()
        {
            return stats.transform(x -> Double.valueOf(x.populationStandardDeviation()).longValue()).orNull();
        }

        @Override
        public String toString()
        {
            return "TasksStats{" +
                    "stats=" + stats +
                    '}';
        }

        static class Builder
        {
            private final List<Long> items = new ArrayList<>();

            void add(long item)
            {
                items.add(item);
            }

            TasksStats build()
            {
                return TasksStats.of(items);
            }
        }
    }

    static class TasksStatsSerializer
            extends StdSerializer<TasksStats>
    {
        protected TasksStatsSerializer()
        {
            super(TasksStats.class);
        }

        @Override
        public void serialize(TasksStats tasksStats, JsonGenerator jsonGenerator, SerializerProvider serializerProvider)
                throws IOException
        {
            jsonGenerator.writeStartObject();
            jsonGenerator.writeObjectField("count", tasksStats.count());
            jsonGenerator.writeObjectField("min", tasksStats.min());
            jsonGenerator.writeObjectField("max", tasksStats.max());
            jsonGenerator.writeObjectField("average", tasksStats.mean());
            jsonGenerator.writeObjectField("stddev", tasksStats.stdDev());
            jsonGenerator.writeEndObject();
        }
    }
}
